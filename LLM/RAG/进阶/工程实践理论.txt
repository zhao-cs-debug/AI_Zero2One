1.RAG是什么？
检索增强生成（RAG）是指对大型语言模型输出进行优化，使其能够在生成响应之前引用训练数据来源之外的权威知识库。
从技术上讲，RAG是基于知识库检索的提示词增强技术。
根据用户输入的信息在数据库中进行查询，将与查询相关的数据，加入到提示词的上下文中，从而提高模型的回答质量。

比较形象的说法是：开卷考试（Open book）

2.RAG有什么优点？
减少LLM幻觉：可以很有效的减少大模型幻觉问题，也就是一本正经胡说八道的现象
数据更安全：相比类似搜索引擎的检索相比，RAG方式，可以更好的利用LLM在安全性上的优势，从而减少了数据泄露的风险（只是作为提示词输入给了LLM，对普通用户并不可见， 需要LLM有针对安全方面的优化）
减少模型微调：使用RAG，可以很方便的使用最新的信息，不需要对模型在最新数据上进行频繁的微调，节省模型训练费用。
当前LLM落地最重要的技术。RAG is currently the best-known tool for grounding LLMs on the latest, verifiable information, and lowering the costs of having to constantly retrain and update them.

3.RAG有哪些挑战？
检索准确性的挑战：客户查询并不总是这么直接，它们可能措辞模糊，如何找到并获取尽可能最相关的信息以供给LLM是要比较大的挑战。
生成调试：如何最好地结构化检索到的信息，从而让LLM产生足够好的响应。（模型上下文大小限制）
LLM能力限制：非常依赖大模型的理解和逻辑能力。

4.RAG应用案例
用户问题：
在一个真实世界的场景中，一位员工，Alice，得知她儿子的学校将在本年度的剩余时间内每周三提前放学。
她想知道她是否可以以半天为单位休假，以及她是否有足够的假期来度过这一年。
RAG处理过程：
为了制定其回应，LLM首先从Alice的HR文件中提取数据，以找出她作为一名长期员工得到多少假期，以及她对于这一年剩下的日子有多少假期。
它还搜索公司的政策，以验证她的假期是否可以以半天为单位来使用。这些事实被注入到Alice的初始查询中，并传递给LLM，它生成了一个简洁、个性化的回答。
一个聊天机器人提供响应，并附上其来源的链接。
挑战：
政策复杂性：产假政策可能会比较复杂，比如它会根据员工办公室所在的州或国家而有所不同。
当LLM找不到准确答案时，它应该回应，“对不起，我不知道”。
模型不喜欢说不知道：通过足够的微调，可以训练LLM在卡住时暂停并说出它的困境。但它可能需要看到数以千计的可以和不能回答的问题的示例。
只有那样，模型才能学会识别一个无法回答的问题，并探索更多细节，直到它遇到它有信息回答的问题。

5.RAG的Embedding模型如何选择？
选择标准有很多，比如模型的性能、处理速度，vector维度大小。我主要从下面两个方面进行的比较：
Huggingface趋势与下载量
实验对比结果
推荐使用：bce-embedding-base_v1，multilingual-e5-large，gte-large-zh，acge_text_embedding


6.Rerank模型是什么？
ReRank模型是对RAG检索返回的结果进行重新排序的模型。
它的作用是对第一步RAG检索出来的chunks，也就是文本进行重新的排序的。
重新排序之后的文本，再给送给LLM来进行处理。

比较形象的说法是：二阶段的检索

7.Rerank模型的作用？
文本Embedding向量存在信息丢失，影响检索准确率
大模型对长文本处理能力的限制
Rerank模型直接通过模型来计算用户问题与文本的相似度，准确度会更高，并让大模型产生更高质量的回答。

8.RAG的Rerank模型如何选择？
选择标准有很多，主要从以下两个方面进行比较：
Huggingface最近一个月下载量
QAnything实验对比结果
推荐使用：bce-reranker-base_v1，bge-reranker-v2-minicpm-layerwise，bge-reranker-large

